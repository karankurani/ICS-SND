@inproceedings{Banerjee2009,
abstract = {Many emerging pathogens infect multiple host species [1], and multi-host pathogens may have very different dynamics in different host species [2]. This research addresses how pathogen replication rates and Immune System (IS) response times are constrained by host body size. An Ordinary Differential Equation (ODE) model is used to show that pathogen replication rates decline with host body size but IS response rates remain invariant with body size. An Agent-Based Model (ABM) is used to investigate two models of IS architecture that could explain scale invariance of IS response rates. A <em>stage structured hybrid model</em> is proposed that strikes a balance between the detailed representation of an ABM and computational tractability of an ODE, by using them in the initial and latter stages of an infection, respectively.},
author = {Banerjee, Soumya and Moses, Melanie E.},
booktitle = {ICARIS: International Conference on Artificial Immune Systems},
pages = {14},
title = {{A Hybrid Agent Based and Differential Equation Model of Body Size Effects on Pathogen Replication and Immune System Response}},
url = {http://portal.acm.org/citation.cfm?id=1615413},
year = {2009}
}
@article{Barrett2005,
abstract = {Suppose terrorists were to release plague in Chicago, and health officials, faced with limited resources and personnel, had to quickly choose the most effective response. Would mass administration of antibiotics be the best way to halt an outbreak?},
author = {Barrett, Chris L. and Eubank, Stephen G. and Smith, James P.},
doi = {10.1038/scientificamerican0305-54},
issn = {0036-8733},
journal = {Scientific American},
month = mar,
number = {3},
pages = {54--61},
publisher = {Scientific American, Inc.},
shorttitle = {Sci Am},
title = {{If Smallpox Strikes Portland ...}},
url = {http://dx.doi.org/10.1038/scientificamerican0305-54},
volume = {292},
year = {2005}
}
@inproceedings{Barrett2008,
abstract = {Preventing and controlling outbreaks of infectious diseases such as pandemic influenza is a top public health priority. We describe EpiSimdemics - a scalable parallel algorithm to simulate the spread of contagion in large, realistic social contact networks using individual-based models. EpiSimdemics is an interaction-based simulation of a certain class of stochastic reaction-diffusion processes. Straightforward simulations of such process do not scale well, limiting the use of individual-based models to very small populations. EpiSimdemics is specifically designed to scale to social networks with 100 million individuals. The scaling is obtained by exploiting the semantics of disease evolution and disease propagation in large networks. We evaluate an MPI-based parallel implementation of EpiSimdemics on a mid-sized HPC system, demonstrating that EpiSimdemics scales well. EpiSimdemics has been used in numerous sponsor defined case studies targeted at policy planning and course of action analysis, demonstrating the usefulness of EpiSimdemics in practical situations.},
author = {Barrett, Christopher L. and Bisset, Keith R. and Eubank, Stephen G. and Feng, Xizhou and Marathe, Madhav V.},
booktitle = {Conference on High Performance Networking and Computing},
title = {{EpiSimdemics: an efficient algorithm for simulating the spread of infectious disease over large realistic social networks}},
url = {http://portal.acm.org/citation.cfm?id=1413370.1413408},
year = {2008}
}
@article{BayardCushing2003,
abstract = {To solve critical biosphere-level problems such as global warming, decreased biodiversity, and natural resource depletion, scientists must integrate data from many researchers. This, in turn, requires better data infrastructure and informatics tools than are currently available. The Canopy Database Project brings together computer scientists and ecologists to develop informatics tools for forest canopy research that meet such ecosystem informatics challenges.},
author = {Bayard, J. and Nadkarni, C. and Kadkarni, N. and Bond, B and Dial, R},
doi = {10.1109/MCISE.2003.1196305},
issn = {1521-9615},
journal = {Computing in Science \& Engineering},
month = may,
number = {3},
pages = {32--43},
title = {{How trees and forests inform biodiversity and ecosystem informatics}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1196305},
volume = {5},
year = {2003}
}
@inproceedings{Bergman2002,
abstract = {Agent-Based Modeling has the capability to become a very powerful tool in economics, but in order to achieve this will require a great deal of effort on the part of its current practitioners. Economics at its core studies people and their actions. This is inherently difficult to do since the motivation of people is not always discernible. A method by which the variety of human behavior could be mimicked, thus providing insight into the process of decision-making that underlies the behaviors, would be invaluable to researchers. Agent-based modeling is such a method. In situations where analytical methods are not sufficient to answer the questions posed, agent-based modeling can be used to obtain solutions to interesting problems, and assess their robustness. However, until the majority of economists accept agent-based modeling as a legitimate tool, the adequacy of the results will remain in question. Certainly one area that will have to be addressed in order to expand the potential of agent-based modeling in economics is sheer exposure. However, more important to its acceptance will be advancements in the cohesiveness of the discipline. The purpose of this note is to present a series of question that must be answered before agent-based modeling can become accepted as a powerful economic tool. },
author = {Bergman, Margo},
booktitle = {Formal Approaches to Agent-Based Systems},
doi = {10.1007/978-3-540-45133-4\_28},
file = {:C$\backslash$:/Documents and Settings/bdilkina/My Documents/Mendeley Desktop//Bergman - 2002 - Evaluating Agent-Based Modeling as a Tool for Economists.pdf:pdf},
pages = {283--285--285},
publisher = {Springer Berlin / Heidelberg},
title = {{Evaluating Agent-Based Modeling as a Tool for Economists}},
url = {http://www.springerlink.com/content/04hv2cq5wvaxyc6t/},
volume = {2699},
year = {2002}
}
@inproceedings{Boriah2008,
abstract = {The study of land cover change is an important problem in the Earth Science domain because of its impacts on local climate, radiation balance, biogeochemistry, hydrology, and the diversity and abundance of terrestrial species. Most well-known change detection techniques from statistics, signal processing and control theory are not well-suited for the massive high-dimensional spatio-temporal data sets from Earth Science due to limitations such as high computational complexity and the inability to take advantage of seasonality and spatio-temporal autocorrelation inherent in Earth Science data. In our work, we seek to address these challenges with new change detection techniques that are based on data mining approaches. Specifically, in this paper we have performed a case study for a new change detection technique for the land cover change detection problem. We study land cover change in the state of California, focusing on the San Francisco Bay Area and perform an extended study on the entire state. We also perform a comparative evaluation on forests in the entire state. These results demonstrate the utility of data mining techniques for the land cover change detection problem.},
author = {Boriah, Shyam and Kumar, Vipin and Steinbach, Michael and Potter, Christopher and Klooster, Steven},
booktitle = {KDD: International Conference on Knowledge Discovery and Data Mining},
keywords = {change detection,land cover,land use,time series},
pages = {857--865},
title = {{Land cover change detection: a case study}},
url = {http://portal.acm.org/citation.cfm?id=1401890.1401993},
year = {2008}
}
@article{Carley2006,
abstract = {While structured by social and institutional networks, disease outbreaks are modulated by physical, economical, technological, communication, health, and governmental infrastructures. To systematically reason about the nature of outbreaks, the potential outcomes of media, prophylaxis, and vaccination campaigns, and the relative value of various early warning devices, social context, and infrastructure, must be considered. Numerical models provide a cost-effective ethical system for reasoning about such events. BioWar, a scalable citywide multiagent network numerical model, is described in this paper. BioWar simulates individuals as agents who are embedded in social, health, and professional networks and tracks the incidence of background and maliciously introduced diseases. In addition to epidemiology, BioWar simulates health-care-seeking behaviors, absenteeism patterns, and pharmaceutical purchases, information useful for syndromic and behavioral surveillance algorithms.},
author = {Carley, K.M. and Fridsma, D.B. and Casman, E. and Yahja, A. and Altman, N. and Kaminsky, B. and Nave, D.},
doi = {10.1109/TSMCA.2005.851291},
issn = {1083-4427},
journal = {IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans},
month = mar,
number = {2},
pages = {252--265},
title = {{BioWar: scalable agent-based model of bioattacks}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1597399},
volume = {36},
year = {2006}
}
@inproceedings{Caruana2006,
abstract = {The Cornell Laboratory of Ornithology's mission is to interpret and conserve the earth's biological diversity through research, education, and citizen science focused on birds. Over the years, the Lab has accumulated one of the largest and longest-running collections of environmental data sets in existence. The data sets are not only large, but also have many attributes, contain many missing values, and potentially are very noisy. The ecologists are interested in identifying which features have the strongest effect on the distribution and abundance of bird species as well as describing the forms of these relationships. We show how data mining can be successfully applied, enabling the ecologists to discover unanticipated relationships. We compare a variety of methods for measuring attribute importance with respect to the probability of a bird being observed at a feeder and present initial results for the impact of important attributes on bird prevalence.},
author = {Caruana, Rich and Elhawary, Mohamed and Munson, Art and Riedewald, Mirek and Sorokina, Daria and Fink, Daniel and Hochachka, Wesley M. and Kelling, Steve},
booktitle = {KDD: International Conference on Knowledge Discovery and Data Mining},
keywords = {attribute importance,bagging,decision trees,model inspection,partial dependence function,sensitivity analysis},
pages = {909--915},
title = {{Mining citizen science data to predict prevalence of wild bird species}},
url = {http://portal.acm.org/citation.cfm?id=1150527},
year = {2006}
}
@inproceedings{Dietterich2007,
abstract = {The emerging field of Ecosystem Informatics applies methods from computer science and mathematics to address fundamental and applied problems in the ecosystem sciences. The ecosystem sciences are in the midst of a revolution driven by a combination of emerging technologies for improved sensing and the critical need for better science to help manage global climate change. This paper describes several initiatives at Oregon State University in ecosystem informatics. At the level of sensor technologies, this paper describes two projects: (a) wireless, battery-free sensor networks for forests and (b) rapid throughput automated arthropod population counting. At the level of data preparation and data cleaning, this paper describes the application of linear gaussian dynamic Bayesian networks to automated anomaly detection in temperature data streams. Finally, the paper describes two educational activities: (a) a summer institute in ecosystem informatics and (b) an interdisciplinary Ph.D. program in Ecosystem Informatics for mathematics, computer science, and the ecosystem sciences.},
author = {Dietterich, Thomas G.},
booktitle = {International conference on Discovery science},
issn = {0302-9743},
pages = {9--25},
title = {{Machine learning in ecosystem informatics}},
url = {http://portal.acm.org/citation.cfm?id=1778945},
year = {2007}
}
@inproceedings{Dilkina2010,
abstract = {We investigate mathematical formulations and solution techniques for a variant of the Connected Subgraph Problem. Given a connected graph with costs and profits associated with the nodes, the goal is to find a connected subgraph that contains a subset of distinguished vertices. In this work we focus on the budget-constrained version, where we maximize the total profit of the nodes in the subgraph subject to a budget constraint on the total cost. We propose several mixed-integer formulations for enforcing the subgraph connectivity requirement, which plays a key role in the combinatorial structure of the problem. We show that a new formulation based on subtour elimination constraints is more effective at capturing the combinatorial structure of the problem, providing significant advantages over the previously considered encoding which was based on a single commodity flow. We test our formulations on synthetic instances as well as on real-world instances of an important problem in environmental conservation concerning the design of wildlife corridors. Our encoding results in a much tighter LP relaxation, and more importantly, it results in finding better integer feasible solutions as well as much better upper bounds on the objective (often proving optimality or within less than 1\% of optimality), both when considering the synthetic instances as well as the real-world wildlife corridor instances.},
author = {Dilkina, Bistra and Gomes, Carla},
booktitle = {CPAIOR: Integration of AI and OR Techniques in Constraint Programming for Combinatorial Optimization Problems},
doi = {10.1007/978-3-642-13520-0},
editor = {Lodi, Andrea and Milano, Michela and Toth, Paolo},
isbn = {978-3-642-13519-4},
pages = {102--116},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Solving Connected Subgraph Problems in Wildlife Conservation}},
url = {http://www.springerlink.com/content/p3741670846g7wh4/},
volume = {6140},
year = {2010}
}
@inproceedings{DiSalvo2010,
abstract = {With the recent growth in sustainable HCI, now is a good time to map out the approaches being taken and the intellectual commitments that underlie the area, to allow for community discussion about where the field should go. Here, we provide an empirical analysis of how sustainable HCI is defining itself as a research field. Based on a corpus of published works, we identify (1) established genres in the area, (2) key unrecognized intellectual differences, and (3) emerging issues, including urgent avenues for further exploration, opportunities for interdisciplinary engagement, and key topics for debate.},
author = {DiSalvo, Carl and Sengers, Phoebe and Brynjarsd\'{o}ttir, Hr\"{o}nn},
booktitle = {CHI: Conference on Human Factors in Computing Systems},
keywords = {reflective hci,sustainability,sustainable hci},
pages = {1975--1984},
title = {{Mapping the landscape of sustainable HCI}},
url = {http://portal.acm.org/citation.cfm?id=1753625},
year = {2010}
}
@article{Duboz2003,
abstract = {This article deals with the coupling of analytical models with individual based models design with the reactive agents paradigm. Such a coupling of models of different natures is motivated by the need to find a way to model scale transfer in large complex systems, i.e. to model how low level of organization can be made to influence upper level and vice versa. This is a fundamental issue, and more particularly in ecological modeling where models are a real scientific tool of investigation. Individuals and populations are not described at the same scale of time and space but it is known that they act on each others. Based on this example, we model individuals in their environment and the population dynamics. While behavior is best modeled using an algorithmic framework (the reactive agent paradigm), population dynamics (because of the number of interacting entities) is best modeled using numerical models. We propose the use of the concept of emergent computation as a framework for coupling heterogeneous formalisms. In the same time, it is crucial to be aware of the consequences of the simplifications and of the choices that are made in the reactive agent model, such as the topology of space and various parameters. In this article, we discuss these issues and our approach on a case study drawn from marine ecology and we show that it is possible to find classical mathematical functional responses with a reactive agent system. Then, we propose a methodology to deal with the coupling of heterogeneous formalism useful in any kind of system modeling.},
author = {Duboz, Rapha\"{e}l and Ramat, \'{E}ric and Preux, Philippe},
issn = {0232-9298},
journal = {Systems Analysis Modelling Simulation},
keywords = {coupling,ecological modeling,formalism heterogeneity,individual-based model,reactive agent model,zooplankton behavior},
number = {6},
pages = {793},
title = {{Scale transfer modeling: using emergent computation for coupling an ordinary differential equation system with a reactive agent model}},
url = {http://portal.acm.org/citation.cfm?id=899773},
volume = {43},
year = {2003}
}
@article{Dudik2007,
abstract = {We present a unified and complete account of maximum entropy density estimation subject to constraints represented by convex potential functions or, alternatively, by convex regularization. We provide fully general performance guarantees and an algorithm with a complete convergence proof. As special cases, we easily derive performance guarantees for many known regularization types, including l1, l2, l22, and l2 + l22 style regularization. We propose an algorithm solving a large and general subclass of generalized maximum entropy problems, including all discussed in the paper, and prove its convergence. Our approach generalizes and unifies techniques based on information geometry and Bregman divergences as well as those based more directly on compactness. Our work is motivated by a novel application of maximum entropy to species distribution modeling, an important problem in conservation biology and ecology. In a set of experiments on real-world data, we demonstrate the utility of maximum entropy in this setting. We explore effects of different feature types, sample sizes, and regularization levels on the performance of maxent, and discuss interpretability of the resulting models.},
author = {Dud\'{\i}k, Miroslav and Phillips, Steven J. and Schapire, Robert E.},
issn = {1532-4435},
journal = {The Journal of Machine Learning Research},
pages = {1217},
title = {{Maximum Entropy Density Estimation with Generalized Regularization and an Application to Species Distribution Modeling}},
url = {http://portal.acm.org/citation.cfm?id=1314498.1314540},
year = {2007}
}
@inproceedings{Eagle2009a,
abstract = {We present txteagle, a system that enables people to earn small amounts of money by completing simple tasks on their mobile phone for corporations who pay them in either airtime or MPESA (mobile money). The system is currently being launched in Kenya and Rwanda in collaboration with the mobile phone service providers Safaricom and MTN Rwanda. Tasks include translation, transcription, and surveys. User studies in Nairobi involving high school students, taxi drivers, and local security guards have been completed and the service has recently launched in Kenya nationwide.},
address = {Berlin, Heidelberg},
author = {Eagle, Nathan},
booktitle = {International Conference on Internationalization, Design and Global Development},
doi = {10.1007/978-3-642-02767-3},
editor = {Aykin, Nuray},
isbn = {978-3-642-02766-6},
pages = {447--456--456},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{txteagle: Mobile Crowdsourcing}},
url = {http://www.springerlink.com/content/x8hrq1h140756nq0/},
volume = {5623},
year = {2009}
}
@inproceedings{Eagle2009,
abstract = {We present a comparative analysis of the behavioral dynamics of rural and urban societies using four years of mobile phone data from all 1.4M subscribers within a small country. We use information from communication logs and top up denominations to characterize attributes such as socioeconomic status and region. We show that rural and urban communities differ dramatically not only in terms of personal network topologies, but also in terms of inferred behavioral characteristics such as travel. We confirm the hypothesis for behavioral adaptation, demonstrating that individuals change their patterns of communication to increase the similarity with their new social environment. To our knowledge, this is the first comprehensive comparison between regional groups of this size.},
author = {Eagle, Nathan and de Montjoye, Yves-Alexandre and Bettencourt, Lu\'{\i}s M.A.},
booktitle = {CSE: International Conference on Computational Science and Engineering},
doi = {10.1109/CSE.2009.91},
isbn = {978-1-4244-5334-4},
month = aug,
pages = {144--150},
publisher = {IEEE},
title = {{Community Computing: Comparisons between Rural and Urban Societies Using Mobile Phone Data}},
url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=5284288},
year = {2009}
}
@article{Eubank2004,
abstract = {Most mathematical models for the spread of disease use differential equations based on uniform mixing assumptions or ad hoc models for the contact process. Here we explore the use of dynamic bipartite graphs to model the physical contact patterns that result from movements of individuals between specific locations. The graphs are generated by large-scale individual-based urban traffic simulations built on actual census, land-use and population-mobility data. We find that the contact network among people is a strongly connected small-world-like graph with a well-defined scale for the degree distribution. However, the locations graph is scale-free, which allows highly efficient outbreak detection by placing sensors in the hubs of the locations network. Within this large-scale simulation framework, we then analyse the relative merits of several proposed mitigation strategies for smallpox spread. Our results suggest that outbreaks can be contained by a strategy of targeted vaccination combined with early detection without resorting to mass vaccination of a population.},
author = {Eubank, Stephen and Guclu, Hasan and Kumar, V S Anil and Marathe, Madhav V and Srinivasan, Aravind and Toroczkai, Zolt\'{a}n and Wang, Nan},
doi = {10.1038/nature02541},
issn = {1476-4687},
journal = {Nature},
keywords = {Contact Tracing,Disease Outbreaks,Disease Outbreaks: prevention \& control,Disease Outbreaks: statistics \& numerical data,Humans,Models, Biological,Smallpox,Smallpox Vaccine,Smallpox: diagnosis,Smallpox: epidemiology,Smallpox: prevention \& control,Smallpox: transmission,Time Factors,Urban Health,Urban Population,Vaccination,Vaccination: methods},
month = may,
number = {6988},
pages = {180--184},
pmid = {15141212},
shorttitle = {Nature},
title = {{Modelling disease outbreaks in realistic urban social networks.}},
url = {http://dx.doi.org/10.1038/nature02541},
volume = {429},
year = {2004}
}
@inproceedings{Krause2007,
abstract = {AI problems such as autonomous robotic exploration, automatic diagnosis and activity recognition have in common the need for choosing among a set of informative but possibly expensive observations. When monitoring spatial phenomena with sensor networks or mobile robots, for example, we need to decide which locations to observe in order to most effectively decrease the uncertainty, at minimum cost. These problems usually are NP-hard. Many observation selection objectives satisfy submodularity, an intuitive diminishing returns property - adding a sensor to a small deployment helps more than adding it to a large deployment. In this paper, we survey recent advances in systematically exploiting this submodularity property to efficiently achieve near-optimal observation selections, under complex constraints. We illustrate the effectiveness of our approaches on problems of monitoring environmental phenomena and water distribution networks.},
author = {Krause, Andreas and Guestrin, Carlos},
booktitle = {AAAI},
keywords = {GP regression,active learning},
mendeley-tags = {GP regression,active learning},
pages = {1650--1654},
title = {{Near-optimal observation selection using submodular functions}},
url = {http://portal.acm.org/citation.cfm?id=1619913},
year = {2007}
}
@inproceedings{springerlink:10.1007/978-3-642-13657-3_2,
abstract = {The climate and earth sciences have recently undergone a rapid transformation from a data-poor to a data-rich environment. In particular, climate and ecosystem related observations from remote sensors on satellites, as well as outputs of climate or earth system models from large-scale computational platforms, provide terabytes of temporal, spatial and spatio-temporal data. These massive and information-rich datasets offer huge potential for understanding and predicting the behavior of the Earth�s ecosystem and for advancing the science of climate change.},
annote = {10.1007/978-3-642-13657-3\_2},
author = {Kumar, Vipin},
booktitle = {PAKDD: Advances in Knowledge Discovery and Data Mining},
editor = {Zaki, Mohammed and Yu, Jeffrey and Ravindran, B and Pudi, Vikram},
pages = {2},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Discovery of Patterns in Global Earth Science Data Using Data Mining}},
url = {http://dx.doi.org/10.1007/978-3-642-13657-3\_2},
volume = {6118},
year = {2010}
}
@inproceedings{Mankoff2007,
abstract = {By its nature, the discipline of human computer interaction must take into consideration the issues that are most pertinent to humans. We believe that the CHI community faces an unanswered challenge in the creation of interactive systems: sustainability. For example, climate scientists argue that the most serious consequences of climate change can be averted, but only if fundamental changes are made. The goal of this SIG is to raise awareness of these issues in the CHI community and to start a conversation about the possibilities and responsibilities we have to address issues of sustainability.},
author = {Mankoff, Jennifer C. and Blevis, Eli and Borning, Alan and Friedman, Batya and Fussell, Susan R. and Hasbrouck, Jay and Woodruff, Allison and Sengers, Phoebe},
booktitle = {CHI: Conference on Human Factors in Computing Systems},
keywords = {energy use,resource consumption,sustainability,value sensitive design},
pages = {2121},
title = {{Environmental sustainability and interaction}},
url = {http://portal.acm.org/citation.cfm?id=1240963},
year = {2007}
}
@article{Mankoff2008,
abstract = {Computer scientists have a role to play in combating global climate change.},
author = {Mankoff, Jennifer and Kravets, Robin and Blevis, Eli},
issn = {0018-9162},
journal = {Computer},
keywords = {climate science,computational energy,invisible computing,sustainability},
number = {8},
pages = {102--105},
title = {{Some Computer Science Issues in Creating a Sustainable World}},
url = {http://portal.acm.org/citation.cfm?id=1447550},
volume = {41},
year = {2008}
}
@article{McRae2008,
abstract = {Connectivity among populations and habitats is important for a wide range of ecological processes. Understanding, preserving, and restoring connectivity in complex landscapes requires connectivity models and metrics that are reliable, efficient, and process based. We introduce a new class of ecological connectivity models based in electrical circuit theory. Although they have been applied in other disciplines, circuit-theoretic connectivity models are new to ecology. They offer distinct advantages over common analytic connectivity models, including a theoretical basis in random walk theory and an ability to evaluate contributions of multiple dispersal pathways. Resistance, current, and voltage calculated across graphs or raster grids can be related to ecological processes (such as individual movement and gene flow) that occur across large population networks or landscapes. Efficient algorithms can quickly solve networks with millions of nodes, or landscapes with millions of raster cells. Here we review basic circuit theory, discuss relationships between circuit and random walk theories, and describe applications in ecology, evolution, and conservation. We provide examples of how circuit models can be used to predict movement patterns and fates of random walkers in complex landscapes and to identify important habitat patches and movement corridors for conservation planning.},
author = {McRae, Brad H and Dickson, Brett G and Keitt, Timothy H and Shah, Viral B},
issn = {0012-9658},
journal = {Ecology},
keywords = {Algorithms,Animals,Biological,Conservation of Natural Resources,Ecology,Ecology: methods,Ecosystem,Evolution,Models,Population Density,Population Dynamics,Theoretical},
month = oct,
number = {10},
pages = {2712--24},
pmid = {18959309},
title = {{Using circuit theory to model connectivity in ecology, evolution, and conservation.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18959309 http://www.circuitscape.org/Circuitscape/Welcome.html},
volume = {89},
year = {2008}
}
@article{Minor2008,
abstract = {Connectivity of habitat patches is thought to be important for movement of genes, individuals, populations, and species over multiple temporal and spatial scales. We used graph theory to characterize multiple aspects of landscape connectivity in a habitat network in the North Carolina Piedmont (U.S.A). We compared this landscape with simulated networks with known topology, resistance to disturbance, and rate of movement. We introduced graph measures such as compartmentalization and clustering, which can be used to identify locations on the landscape that may be especially resilient to human development or areas that may be most suitable for conservation. Our analyses indicated that for songbirds the Piedmont habitat network was well connected. Furthermore, the habitat network had commonalities with planar networks, which exhibit slow movement, and scale-free networks, which are resistant to random disturbances. These results suggest that connectivity in the habitat network was high enough to prevent the negative consequences of isolation but not so high as to allow rapid spread of disease. Our graph-theory framework provided insight into regional and emergent global network properties in an intuitive and visual way and allowed us to make inferences about rates and paths of species movements and vulnerability to disturbance. This approach can be applied easily to assessing habitat connectivity in any fragmented or patchy landscape.},
author = {Minor, Emily and Urban, Dean},
doi = {10.1111/j.1523-1739.2007.00871.x},
issn = {1523-1739},
journal = {Conservation biology},
keywords = {Conservation of Natural Resources,Conservation of Natural Resources: methods,Ecosystem,Geography,Models,North Carolina,Population Dynamics,Theoretical,reserve design},
mendeley-tags = {reserve design},
number = {2},
pages = {297--307},
publisher = {Blackwell Publishing},
shorttitle = {Conserv Biol},
title = {{A graph-theory framework for evaluating landscape connectivity and conservation planning.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18241238},
volume = {22},
year = {2008}
}
@article{Onal2008,
abstract = {Habitat fragmentation is often cited as one of the most important factors that adversely affect species persistence and survival ability. Contiguity of habitat sites is usually desirable when designing a conservation reserve. If a contiguous reserve is not feasible, due to landscape characteristics or economic constraints, designing a reserve network with minimal fragmentation may be a viable strategy. This article presents a linear integer programming formulation of the problem using graph theory concepts. A graph is constructed where nodes correspond to individual sites and directed arcs are defined for pairs of nodes corresponding to adjacent sites. The model determines a minimal representative tree as a subgraph where each node in the tree corresponds to either a selected reserve site or a gap site. Reserve fragmentation is defined as the sum of gap sites, which is to be minimized. An important computational problem is the formation of cycles when determining the minimal representative tree. This problem is resolved using an iterative procedure that utilizes Dantzig-cuts when a cycle occurs in the solution. Arbitrarily generated data sets are used to explore the computational efficiency of this approach. Finally an empirical application of the model to a real data set involving 744 sites and 32 endangered-threatened bird species is presented. ? 2007 Wiley Periodicals, Inc. NETWORKS, 2008},
address = {New York, NY, USA},
author = {Onal, Hayri and Wang, Yicheng},
doi = {http://dx.doi.org/10.1002/net.v51:2},
issn = {0028-3045},
journal = {Networks},
number = {2},
pages = {142--152},
publisher = {Wiley-Interscience},
title = {{A graph theory approach for designing conservation reserve networks with minimal fragmentation}},
url = {http://www3.interscience.wiley.com/cgi-bin/fulltext/117864351/PDFSTART},
volume = {51},
year = {2008}
}
@inproceedings{Parr2006,
abstract = {We describe ELVIS (the Ecosystem Location Visualization and Information System), a suite of tools for constructing food webs for a given location. We express both ELVIS input and output data in OWL, thereby enabling its integration with other semantic web resources. In particular, we describe using a Triple Shop application to answer SPARQL queries from a collection of semantic web documents. This is an end-to-end case study of the semantic web's utility for ecological and environmental research.},
address = {New York, NY, USA},
author = {Parr, Cynthia Sims and Parafiynyk, Andriy and Sachs, Joel and Ding, Li and Dornbush, Sandor and Finin, Tim and Wang, David and Hollander, Allan},
booktitle = {WWW: International conference on World Wide Web},
doi = {http://doi.acm.org/10.1145/1135777.1136021},
isbn = {1-59593-323-9},
pages = {1073--1074},
publisher = {ACM},
title = {{Integrating ecoinformatics resources on the semantic web}},
url = {http://doi.acm.org/10.1145/1135777.1136021},
year = {2006}
}
@inproceedings{Patnaik2010,
abstract = {We present a data mining approach to model the cooling infrastructure in data centers, particularly the chiller ensemble. These infrastructures are poorly understood due to the lack of  first principles  models of chiller systems. At the same time, they abound in data due to instrumentation by modern sensor networks. We present a multi-level framework to transduce sensor streams into an actionable dynamic Bayesian network model of the system. This network is then used to explain observed system transitions and aid in diagnostics and prediction. We showcase experimental results using a HP data center in Bangalore, India.},
address = {Berlin, Heidelberg},
author = {Patnaik, Debprakash and Marwah, Manish and Sharma, Ratnesh and Ramakrishnan, Naren},
booktitle = {Advances in Intelligent Data Analysis},
doi = {10.1007/978-3-642-13062-5},
editor = {Cohen, Paul R. and Adams, Niall M. and Berthold, Michael R.},
isbn = {978-3-642-13061-8},
pages = {125--136--136},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Data Mining for Modeling Chiller Systems in Data Centers }},
url = {http://www.springerlink.com/content/vx56nu2252747055/},
volume = {6065},
year = {2010}
}
@inproceedings{Patnaik2009,
abstract = {Motivation: Data centers are a critical component of modern IT infrastructure but are also among the worst environmental offenders through their increasing energy usage and the resulting large carbon footprints. Efficient management of data centers, including power management, networking, and cooling infrastructure, is hence crucial to sustainability. In the absence of a 'first-principles' approach to manage these complex components and their interactions, data-driven approaches have become attractive and tenable. Results: We present a temporal data mining solution to model and optimize performance of data center chillers, a key component of the cooling infrastructure. It helps bridge raw, numeric, time-series information from sensor streams toward higher level characterizations of chiller behavior, suitable for a data center engineer. To aid in this transduction, temporal data streams are first encoded into a symbolic representation, next run-length encoded segments are mined to form frequent motifs in time series, and finally these metrics are evaluated by their contributions to sustainability. A key innovation in our application is the ability to intersperse "don't care" transitions (e.g., transients) in continuous-valued time series data, an advantage we inherit by the application of frequent episode mining to symbolized representations of numeric time series. Our approach provides both qualitative and quantitative characterizations of the sensor streams to the data center engineer, to aid him in tuning chiller operating characteristics. This system is currently being prototyped for a data center managed by HP and experimental results from this application reveal the promise of our approach.},
author = {Patnaik, Debprakash and Marwah, Manish and Sharma, Ratnesh and Ramakrishnan, Naren},
booktitle = {KDD: International Conference on Knowledge Discovery and Data Mining},
keywords = {chillers,clustering,data centers,frequent episodes,motifs,sustainability},
pages = {1305--1314},
title = {{Sustainable operation and management of data center chillers using temporal data mining}},
url = {http://portal.acm.org/citation.cfm?doid=1557019.1557159},
year = {2009}
}
@inproceedings{Phillips2004,
abstract = {We study the problem of modeling species geographic distributions, a critical problem in conservation biology. We propose the use of maximum-entropy techniques for this problem, specifically, sequential-update algorithms that can handle a very large number of features. We describe experiments comparing maxent with a standard distribution-modeling tool, called GARP, on a dataset containing observation data for North American breeding birds. We also study how well maxent performs as a function of the number of training examples and training time, analyze the use of regularization to avoid overfitting when the number of examples is small, and explore the interpretability of models constructed using maxent.},
author = {Phillips, Steven J. and Dud\'{\i}k, Miroslav and Schapire, Robert E.},
booktitle = {ICML: ACM Iinternational conference on Machine learning},
pages = {83},
title = {{A maximum entropy approach to species distribution modeling}},
url = {http://portal.acm.org/citation.cfm?id=1015330.1015412},
year = {2004}
}
@inproceedings{Sheldon2007,
abstract = {We investigate a family of inference problems on Markov models, where many sample paths are drawn from a Markov chain and partial information is revealed to an observer who attempts to reconstruct the sample paths. We present algorithms and hardness results for several variants of this problem which arise by revealing different information to the observer and imposing different requirements for the reconstruction of sample paths. Our algorithms are analogous to the classical Viterbi algorithm for Hidden Markov Models, which finds single most probable sample path given a sequence of observations. Our work is motivated by an important application in ecology: inferring bird migration paths from a large database of observations.},
author = {Sheldon, Daniel and Elmohamed, M. A. Saleh and Kozen, Dexter},
booktitle = {NIPS},
title = {{Collective Inference on Markov Models for Modeling Bird Migration.}},
url = {http://dblp.uni-trier.de/db/conf/nips/nips2007.html\#SheldonEK07},
year = {2007}
}
@inproceedings{Steinbach2003,
abstract = {To analyze the effect of the oceans and atmosphere on land climate, Earth Scientists have developed climate indices, which are time series that summarize the behavior of selected regions of the Earth's oceans and atmosphere. In the past, Earth scientists have used observation and, more recently, eigenvalue analysis techniques, such as principal components analysis (PCA) and singular value decomposition (SVD), to discover climate indices. However, eigenvalue techniques are only useful for finding a few of the strongest signals. Furthermore, they impose a condition that all discovered signals must be orthogonal to each other, making it difficult to attach a physical interpretation to them. This paper presents an alternative clustering-based methodology for the discovery of climate indices that overcomes these limitiations and is based on clusters that represent regions with relatively homogeneous behavior. The centroids of these clusters are time series that summarize the behavior of the ocean or atmosphere in those regions. Some of these centroids correspond to known climate indices and provide a validation of our methodology; other centroids are variants of known indices that may provide better predictive power for some land areas; and still other indices may represent potentially new Earth science phenomena. Finally, we show that cluster based indices generally outperform SVD derived indices, both in terms of area weighted correlation and direct correlation with the known indices.},
author = {Steinbach, Michael and Tan, Pang-Ning and Kumar, Vipin and Klooster, Steven and Potter, Christopher},
booktitle = {KDD: International Conference on Knowledge Discovery and Data Mining},
keywords = {clustering,earth science data,mining scientific data,singular value decomposition,time series},
pages = {446},
title = {{Discovery of climate indices using clustering}},
url = {http://portal.acm.org/citation.cfm?id=956750.956801},
year = {2003}
}
@inproceedings{Vytelingum2010,
abstract = {The Intelligent Decentralised Energy-Aware Systems (iDEaS) project at the University of Southampton (see www.ideasproject.info) is developing and demonstrating the application of intelligent agents within the smart grid; a future vision of an electricity distribution network capable of autonomous and intelligent configuration, robust and flexible operation, and two-way information flow between consumers and suppliers. In this demonstration, we show how agent technologies can assist in realising three key components of this vision, specifically: (i) how a home energy management agent is capable of monitoring, visualising and coordinating energy use within the home, (ii) how micro-storage of electricity, coordinated by intelligent agents, can flattern demand across the grid and reduce both costs and carbon emissions, and (iii) how trading agents operating within a novel market mechanism can effectively and robustly distribute energy within the smart grid whilst explicitly accounting for the capacity constraints of the transmission lines.},
author = {Vytelingum, P. and Voice, T. D. and Ramchurn, S. D. and Rogers, A. and Jennings, N. R.},
booktitle = {AAMAS: International Conference on Autonomous Agents and Multi Agent Systems},
keywords = {agent,electricity,smart grid,storage,trading},
pages = {1649--1650},
title = {{Intelligent agents for the smart grid}},
url = {http://portal.acm.org/citation.cfm?id=1838524},
year = {2010}
}
@inproceedings{Vytelingum2010a,
abstract = {The use of energy storage devices in homes has been advocated as one of the main ways of saving energy and reducing the reliance on fossil fuels in the future Smart Grid. However, if micro-storage devices are all charged at the same time using power from the electricity grid, it means a higher demand and, hence, requires more generation capacity, results in more carbon emissions, and, in the worst case, breaks down the system due to over-demand. To alleviate such issues, in this paper, we present a novel agent-based micro-storage management technique that allows all (individually-owned) storage devices in the system to converge to profitable, efficient behaviour. Specifically, we provide a general framework within which to analyse the Nash equilibrium of an electricity grid and devise new agent-based storage learning strategies that adapt to market conditions. Taken altogether, our solution shows that, specifically, in the UK electricity market, it is possible to achieve savings of up to 13\% on average for a consumer on his electricity bill with a storage device of 4 kWh. Moreover, we show that there exists an equilibrium where only 38\% of UK households would own storage devices and where social welfare would be also maximised (with an overall annual savings of nearly GBP 1.5B at that equilibrium).},
author = {Vytelingum, Perukrishnen and Voice, Thomas D. and Ramchurn, Sarvapali D. and Rogers, Alex and Jennings, Nicholas R.},
booktitle = {AAMAS: International Conference on Autonomous Agents and Multi Agent Systems},
keywords = {agent-based simulation,energy,micro-storage,smart grid},
pages = {39--46},
title = {{Agent-based micro-storage management for the Smart Grid}},
url = {http://portal.acm.org/citation.cfm?id=1838212},
year = {2010}
}
@article{Williams2008488,
abstract = {
The reserve set covering problem minimizes the total cost or area of sites needed to represent all species within a system of nature reserves, but does not address spatial characteristics such as distances between reserve sites. Inter-site distance, as a surrogate for connectivity, is likely to affect species persistence and other functional aspects of reserve systems. Two new 0-1 programming models that build upon the reserve set covering problem are formulated for controlling inter-site distance. Depending on the circumstances, longer or shorter inter-site distances may be desirable, and arguments for each case are discussed. The first model requires reserves to be at least a minimum separation distance apart. The second model requires at least two representations of each species and also requires the sites that represent a species to be no farther apart than a stated proximity distance. These models are applied to four demonstration problems in which both synthetic and real presence/absence data are used. Results and computational experience are discussed. The first model achieves site dispersal while the second model achieves site connectivity to the extent that each is compatible with set covering.},
annote = {Part Special Issue: Location Modeling Dedicated to the memory of Charles S. ReVelle},
author = {Williams, Justin C},
doi = {DOI: 10.1016/j.cor.2006.03.012},
issn = {0305-0548},
journal = {Computers \& Operations Research},
keywords = {Integer programming,reserve design},
mendeley-tags = {reserve design},
pages = {488--498},
title = {{Optimal reserve site selection with distance requirements}},
url = {http://www.sciencedirect.com/science/article/B6VC5-4JSFVGV-2/2/32ee37f43cc4a4423299a79f3da1f604},
volume = {35},
year = {2008}
}
@article{Williams2006,
abstract = {Rapid advances in information technologies continue to drive a flood of data and analysis techniques in ecological and environmental sciences. Using these resources more effectively and taking advantage of associated cross-disciplinary research opportunities poses a major challenge to both scientists and information technologists. These challenges are now being addressed in projects that apply knowledge representation and Semantic Web technologies to problems in discovering and integrating ecological data and data analysis techniques. In this paper, we present an overview of the major ontological components of our project, SEEK (''Science Environment for Ecological Knowledge''). We describe the concepts and models that are represented in each, and present a discussion of potential applications of these ontologies on the Semantic Web.},
author = {Williams, Richard J. and Martinez, Neo D. and Golbeck, Jennifer},
issn = {1570-8268},
journal = {Web Semantics: Science, Services and Agents on the World Wide Web},
keywords = {Ecoinformatics,Ecology,Ontologies,Semantic Web},
number = {4},
pages = {237--242},
title = {{Ontologies for ecoinformatics}},
url = {http://portal.acm.org/citation.cfm?id=1222406},
volume = {4},
year = {2006}
}
